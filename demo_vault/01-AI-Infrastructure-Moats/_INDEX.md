---
insight_count: 3
last_updated: '2025-02-01'
theme: AI Infrastructure Moats
type: index
---

# AI Infrastructure Moats - Index

## Overview
Analysis of defensibility in AI infrastructure — GPU cloud economics, inference optimization, and model serving architectures that create lasting competitive advantages.

---

## Recent Insights

- [[gpu-cloud-lock-in]] — How GPU cloud contracts create switching costs
- [[inference-cost-curves]] — The economics of inference at scale
- [[model-serving-architectures]] — Architectural patterns for model deployment

---

## Key Concepts

- GPU utilization economics
- Inference cost optimization
- Custom silicon moats
- Model serving at scale
- Cloud provider lock-in dynamics

---

## Related Themes

- [[_INDEX|Enterprise AI Adoption]] — Infrastructure decisions impact enterprise rollouts
- [[_INDEX|VC Pattern Recognition]] — Infrastructure moats as investment signals
